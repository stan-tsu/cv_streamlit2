import streamlit as st
import torch
import numpy as np
from PIL import Image
import segmentation_models_pytorch as smp
import requests
from io import BytesIO
import os

st.set_page_config(page_title="–°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –ª–µ—Å–∞ (ResNet34 Unet)", layout="wide")
st.title("üå≤ –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –ª–µ—Å–∞ –Ω–∞ –∞—ç—Ä–æ—Ñ–æ—Ç–æ—Å–Ω–∏–º–∫–∞—Ö (Unet + ResNet34)")

# --- –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ ---
@st.cache_resource
def load_model():
    model = smp.Unet(
        encoder_name="resnet34",
        encoder_weights=None,  # –≤–µ—Å–∞ —ç–Ω–∫–æ–¥–µ—Ä–∞ –Ω–µ –Ω—É–∂–Ω—ã, —Ç.–∫. –º—ã –≥—Ä—É–∑–∏–º —Å–≤–æ–∏ –≤–µ—Å–∞
        in_channels=3,
        classes=1,
        activation=None
    )
    model.load_state_dict(torch.load("best_model-3.pth", map_location="cpu"))
    model.eval()
    return model

model = load_model()

# --- –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º –∏–ª–∏ –ø–æ —Å—Å—ã–ª–∫–µ ---
st.header("1. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏")
uploaded_files = st.file_uploader(
    "–í—ã–±–µ—Ä–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–º–æ–∂–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ)",
    type=["jpg", "jpeg", "png"],
    accept_multiple_files=True
)

st.subheader("–∏–ª–∏ —É–∫–∞–∂–∏—Ç–µ –ø—Ä—è–º—É—é —Å—Å—ã–ª–∫—É –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")
img_url = st.text_input("URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")

images = []
if uploaded_files:
    for file in uploaded_files:
        img = Image.open(file).convert("RGB")
        images.append((img, file.name))
elif img_url:
    try:
        response = requests.get(img_url)
        img = Image.open(BytesIO(response.content)).convert("RGB")
        images.append((img, "from_url.jpg"))
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")

# --- –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è ---
def predict_mask(img, model):
    import torchvision.transforms as T
    transform = T.Compose([
        T.Resize((256, 256)),
        T.ToTensor(),
    ])
    image_tensor = transform(img).unsqueeze(0)
    with torch.no_grad():
        pred_logits = model(image_tensor)
        pred_mask = (torch.sigmoid(pred_logits) > 0.5).float()
    return pred_mask.squeeze().cpu().numpy()

if images:
    st.header("2. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏")
    cols = st.columns(len(images))
    for idx, (img, name) in enumerate(images):
        with cols[idx]:
            st.image(img, caption=f"–ò—Å—Ö–æ–¥–Ω–æ–µ: {name}", use_container_width=True)
            mask = predict_mask(img, model)
            st.image(mask, caption="–ú–∞—Å–∫–∞ –ª–µ—Å–∞", use_container_width=True, clamp=True)
            # –ù–∞–ª–æ–∂–µ–Ω–∏–µ –º–∞—Å–∫–∏ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            img_np = np.array(img.resize((256, 256)))
            overlay = img_np.copy()
            overlay[mask > 0.5] = [0, 255, 0]  # –∑–µ–ª—ë–Ω—ã–π —Ü–≤–µ—Ç –¥–ª—è –ª–µ—Å–∞
            st.image(overlay, caption="–°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è (–Ω–∞–ª–æ–∂–µ–Ω–∏–µ)", use_container_width=True)


st.markdown("""
---
**–ú–æ–¥–µ–ª—å:**  
Unet —Å —ç–Ω–∫–æ–¥–µ—Ä–æ–º ResNet-34 (–ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –≤–µ—Å–∞ ImageNet).  
–§–∞–π–ª –≤–µ—Å–æ–≤: `best_model-3.pth`.

**–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:**  
- –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥—Ä—É–≥–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–º U-Net.
- –≠–Ω–∫–æ–¥–µ—Ä ResNet-34 –ø–æ–∑–≤–æ–ª—è–µ—Ç –ª—É—á—à–µ –∏–∑–≤–ª–µ–∫–∞—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.
- –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –ø—Ä–æ–≤–æ–¥–∏—Ç—Å—è –ø–æ —Ç–µ–º –∂–µ –¥–∞–Ω–Ω—ã–º, —á—Ç–æ –∏ –Ω–∞ –ø—Ä–µ–¥—ã–¥—É—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ.
""")